{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494021, 42)\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv('kddcup.data_10_percent_corrected')\n",
    "labels = pd.read_csv(\"labels.csv\",sep = \":\",header = None)\n",
    "data   = pd.read_csv(\"kddcup.data_10_percent_corrected\", names = labels.iloc[:,0].values)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
      "0         0           tcp    http   SF        181       5450     0   \n",
      "1         0           tcp    http   SF        239        486     0   \n",
      "2         0           tcp    http   SF        235       1337     0   \n",
      "3         0           tcp    http   SF        219       1337     0   \n",
      "4         0           tcp    http   SF        217       2032     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot   ...     dst_host_srv_count  \\\n",
      "0               0       0    0   ...                      9   \n",
      "1               0       0    0   ...                     19   \n",
      "2               0       0    0   ...                     29   \n",
      "3               0       0    0   ...                     39   \n",
      "4               0       0    0   ...                     49   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                     1.0                     0.0   \n",
      "1                     1.0                     0.0   \n",
      "2                     1.0                     0.0   \n",
      "3                     1.0                     0.0   \n",
      "4                     1.0                     0.0   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                         0.11                          0.0   \n",
      "1                         0.05                          0.0   \n",
      "2                         0.03                          0.0   \n",
      "3                         0.03                          0.0   \n",
      "4                         0.02                          0.0   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                   0.0                       0.0                   0.0   \n",
      "1                   0.0                       0.0                   0.0   \n",
      "2                   0.0                       0.0                   0.0   \n",
      "3                   0.0                       0.0                   0.0   \n",
      "4                   0.0                       0.0                   0.0   \n",
      "\n",
      "   dst_host_srv_rerror_rate   output  \n",
      "0                       0.0  normal.  \n",
      "1                       0.0  normal.  \n",
      "2                       0.0  normal.  \n",
      "3                       0.0  normal.  \n",
      "4                       0.0  normal.  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,41] = np.where(data.iloc[:,41] != 'normal.',1,data.iloc[:,41])\n",
    "data.iloc[:,41] = np.where(data.iloc[:,41] == 'normal.',0,data.iloc[:,41])\n",
    "\n",
    "data.iloc[:,41].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "cat_columns = labels.loc[labels.iloc[:,1] == \" symbolic.\",0].values\n",
    "data[cat_columns] = data[cat_columns].apply(lambda col: lb_make.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffr(df, t):\n",
    "    classes = ['normal', 'u2r', 'dos', 'r2l', 'probe']\n",
    "    classes2 = [0,1]\n",
    "    df_new = df.iloc[:,:-1]\n",
    "    var_d = []\n",
    "    for clas in classes2:\n",
    "        temp = df.loc[df['output'] == clas]\n",
    "        #print(\"is unique \", temp.output.unique())\n",
    "        temp = temp.iloc[:,:-1].values\n",
    "        #print(\"temp = \", temp)\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        temp_scaled = min_max_scaler.fit_transform(temp)\n",
    "        #print(\"temp_scaled = \", temp_scaled)\n",
    "        mean_ind = temp_scaled.mean(axis = 0)\n",
    "        #print(\"mean_ind = \", mean_ind)\n",
    "        var_d_f = np.square(mean_ind - temp).mean(axis = 0)\n",
    "        #print(\"var_d_f_f = \", var_d_f)\n",
    "        var_d.append(var_d_f)\n",
    "    var_d = np.array(var_d)\n",
    "    #print(var_d)\n",
    "    var_d_mean = var_d.mean(axis = 0)\n",
    "    \n",
    "    \n",
    "#     var = np.zeros(len(mean_means))\n",
    "#     for i in means:\n",
    "#         var += np.square(i - mean_means)\n",
    "#     var /= len(mean_means)\n",
    "#     #print(var)\n",
    "    indexes = list(np.argsort(var_d_mean))\n",
    "    filtered_indexes = indexes[:t]\n",
    "    filtered_indexes.append(41)\n",
    "    filtered_data = df.iloc[:, filtered_indexes]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ffr(data,30)\n",
    "print(\"With FFS with number of features : \",30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "Y = data.iloc[:,-1]\n",
    "Y = np.array(Y)\n",
    "#Y = Y.reshape(Y.shape[0],1)\n",
    "print(Y.shape)\n",
    "data.drop(data.columns[-1], axis=1, inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, Y, test_size = 0.20) \n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "#Y_train = Y_train.reshape(Y_train.shape[0],1)\n",
    "Y_test = np.array(Y_test)\n",
    "#Y_test = Y_test.reshape(Y_test.shape[0],1)\n",
    "\n",
    "print(\"X_train : \",X_train.shape)\n",
    "print(\"X_test : \",X_test.shape)\n",
    "print(\"Y_train : \",Y_train.shape)\n",
    "print(\"Y_test : \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing in order to do the computation faster doing scaling can use MinMaxScaler as well...\n",
    "# Check how SVM learns in terms of distance calculation\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "print(\"X_train Shape : \", X_train.shape)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "Y_train = encoder.transform(Y_train)\n",
    "print(\"Y_train Shape : \",Y_train.shape)\n",
    "\n",
    "X_test = X_test.astype(float)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(\"X_train Shape : \", X_train.shape)\n",
    "\n",
    "Y_test = encoder.transform(Y_test)\n",
    "print(\"Y_test Shape : \",Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "svm_model = svm.SVC(kernel='linear',C=1.0)\n",
    "\n",
    "start = time.time()\n",
    "svm_model.fit(X_train,Y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Training Time for Binary SVM : \", (end - start))\n",
    "\n",
    "# Predicting the Results\n",
    "\n",
    "predicted = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Done Predicting..\")\n",
    "\n",
    "\n",
    "predicted = predicted.ravel()\n",
    "#print(len(predicted))\n",
    "Y_predicted = np.empty((len(predicted),))\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] < 0.5:\n",
    "        Y_predicted[i] = 0\n",
    "        #Y_predicted[i] = (Y_predicted[i])\n",
    "    else:\n",
    "        Y_predicted[i] = 1\n",
    "        #Y_predicted[i] = math.floor(Y_predicted[i])\n",
    "\n",
    "Y_predicted = Y_predicted.astype(int)\n",
    "Y_test_final = np.array(Y_test)\n",
    "print(Y_predicted.shape)\n",
    "print(Y_test_final.shape)\n",
    "print(type(Y_predicted))\n",
    "print(type(Y_test_final))\n",
    "\n",
    "print(\"Y_predicted Unique and its Frequency :\")\n",
    "y_pre,y_pred_counts = np.unique(Y_predicted,return_counts=True)\n",
    "print(y_pre,y_pred_counts)\n",
    "\n",
    "print(\"Y_test Final unique and its Frequency : \")\n",
    "y_test_final,y_test_counts = np.unique(Y_test_final,return_counts=True)\n",
    "print(y_test_final,y_test_counts)\n",
    "\n",
    "\n",
    "tp,fp,tn,fn = 0,0,0,0\n",
    "for i in range(len(Y_test_final)):\n",
    "    if Y_test_final[i] == Y_predicted[i] and Y_test_final[i] == 1:\n",
    "        tp = tp + 1\n",
    "    elif Y_test_final[i] == Y_predicted[i] and Y_test_final[i] == 0:\n",
    "        tn = tn + 1\n",
    "    elif Y_test_final[i] != Y_predicted[i] and Y_test_final[i] == 0:\n",
    "        fp = fp + 1\n",
    "    else:\n",
    "        fn = fn + 1\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = (2*precision*recall)/(precision + recall)\n",
    "print(\"tp :\",tp)\n",
    "print(\"tn :\",tn)\n",
    "print(\"fp :\",fp)\n",
    "print(\"fn :\",fn)\n",
    "print(\"Accuracy : \",accuracy)\n",
    "print(\"Precision : \",precision)\n",
    "print(\"Recall : \",recall)\n",
    "print(\"f1_score : \",f1_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RBF Kernel\n",
    "\n",
    "svm_model = svm.SVC(kernel='rbf',C=1.0)\n",
    "svm_model.fit(X_train,Y_train)\n",
    "print(\"Done Modelling...\")\n",
    "\n",
    "# Predicting the Results\n",
    "\n",
    "predicted = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Done Predicting..\")\n",
    "\n",
    "\n",
    "predicted = predicted.ravel()\n",
    "#print(len(predicted))\n",
    "Y_predicted = np.empty((len(predicted),))\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] < 0.5:\n",
    "        Y_predicted[i] = 0\n",
    "        #Y_predicted[i] = (Y_predicted[i])\n",
    "    else:\n",
    "        Y_predicted[i] = 1\n",
    "        #Y_predicted[i] = math.floor(Y_predicted[i])\n",
    "\n",
    "Y_predicted = Y_predicted.astype(int)\n",
    "Y_test_final = np.array(Y_test)\n",
    "print(Y_predicted.shape)\n",
    "print(Y_test_final.shape)\n",
    "print(type(Y_predicted))\n",
    "print(type(Y_test_final))\n",
    "\n",
    "print(\"Y_predicted Unique and its Frequency :\")\n",
    "y_pre,y_pred_counts = np.unique(Y_predicted,return_counts=True)\n",
    "print(y_pre,y_pred_counts)\n",
    "\n",
    "print(\"Y_test Final unique and its Frequency : \")\n",
    "y_test_final,y_test_counts = np.unique(Y_test_final,return_counts=True)\n",
    "print(y_test_final,y_test_counts)\n",
    "\n",
    "\n",
    "tp,fp,tn,fn = 0,0,0,0\n",
    "for i in range(len(Y_test_final)):\n",
    "    if Y_test_final[i] == Y_predicted[i] and Y_test_final[i] == 1:\n",
    "        tp = tp + 1\n",
    "    elif Y_test_final[i] == Y_predicted[i] and Y_test_final[i] == 0:\n",
    "        tn = tn + 1\n",
    "    elif Y_test_final[i] != Y_predicted[i] and Y_test_final[i] == 0:\n",
    "        fp = fp + 1\n",
    "    else:\n",
    "        fn = fn + 1\n",
    "\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1_score = (2*precision*recall)/(precision + recall)\n",
    "print(\"tp :\",tp)\n",
    "print(\"tn :\",tn)\n",
    "print(\"fp :\",fp)\n",
    "print(\"fn :\",fn)\n",
    "print(\"Accuracy : \",accuracy)\n",
    "print(\"Precision : \",precision)\n",
    "print(\"Recall : \",recall)\n",
    "print(\"f1_score : \",f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
