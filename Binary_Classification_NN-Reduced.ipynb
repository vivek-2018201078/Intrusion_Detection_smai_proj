{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('kddcup.data_10_percent_corrected')\n",
    "#data\n",
    "labels = pd.read_csv(\"labels.csv\",sep = \":\",header = None)\n",
    "data   = pd.read_csv(\"kddcup.data_10_percent_corrected\", names = labels.iloc[:,0].values)\n",
    "data_onehotencoded = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "cat_columns = labels.loc[labels.iloc[:,1] == \" symbolic.\",0].values\n",
    "data[cat_columns] = data[cat_columns].apply(lambda col: lb_make.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,-1] = np.where(data.iloc[:,-1] != 'normal.',1,data.iloc[:,-1])\n",
    "data.iloc[:,-1] = np.where(data.iloc[:,-1] == 'normal.',0,data.iloc[:,-1])\n",
    "\n",
    "data.iloc[:,-1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffr(df, t):\n",
    "    classes = ['normal', 'u2r', 'dos', 'r2l', 'probe']\n",
    "    classes2 = [0,1]\n",
    "    df_new = df.iloc[:,:-1]\n",
    "    var_d = []\n",
    "    for clas in classes2:\n",
    "        temp = df.loc[df['output'] == clas]\n",
    "        #print(\"is unique \", temp.output.unique())\n",
    "        temp = temp.iloc[:,:-1].values\n",
    "        #print(\"temp = \", temp)\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        temp_scaled = min_max_scaler.fit_transform(temp)\n",
    "        #print(\"temp_scaled = \", temp_scaled)\n",
    "        mean_ind = temp_scaled.mean(axis = 0)\n",
    "        #print(\"mean_ind = \", mean_ind)\n",
    "        var_d_f = np.square(mean_ind - temp).mean(axis = 0)\n",
    "        #print(\"var_d_f_f = \", var_d_f)\n",
    "        var_d.append(var_d_f)\n",
    "    var_d = np.array(var_d)\n",
    "    #print(var_d)\n",
    "    var_d_mean = var_d.mean(axis = 0)\n",
    "    \n",
    "    \n",
    "#     var = np.zeros(len(mean_means))\n",
    "#     for i in means:\n",
    "#         var += np.square(i - mean_means)\n",
    "#     var /= len(mean_means)\n",
    "#     #print(var)\n",
    "    indexes = list(np.argsort(var_d_mean))\n",
    "    filtered_indexes = indexes[:t]\n",
    "    filtered_indexes.append(41)\n",
    "    filtered_data = df.iloc[:, filtered_indexes]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(data,feature):\n",
    "    epoch = 100\n",
    "    batchsize = 32\n",
    "\n",
    "    data = data.sample(frac=1,random_state=200)\n",
    "    Input1 = data.iloc[:,:41]\n",
    "    Output1 = data.iloc[:,-1]\n",
    "    Input1 = np.array(Input1)\n",
    "    Output1 = np.array(Output1)\n",
    "    Output1 = Output1.reshape(Output1.shape[0],1)\n",
    "    print(np.unique(Output1))\n",
    "    print(Input1.shape)\n",
    "    print(Output1.shape)\n",
    "    print(type(Input1))\n",
    "    print(type(Output1))\n",
    "    Input1 = Input1.astype(float)\n",
    "    split = int(math.ceil(0.8 * len(Input1)))\n",
    "    X_train = Input1[0:split]\n",
    "    Y_train = Output1[0:split]\n",
    "\n",
    "    X_test = Input1[split:]\n",
    "    Y_test = Output1[split:]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(Y_test.shape)\n",
    "    flatten_Y_train = Y_train.ravel()\n",
    "    class_weights = class_weight.compute_class_weight('balanced' ,np.unique(Y_train) ,flatten_Y_train)\n",
    "    inp = Input(shape=(feature,))\n",
    "    hidden1 = Dense(40,activation='sigmoid')(inp)\n",
    "    hidden2 = Dense(40,activation='sigmoid')(hidden1)\n",
    "    out = Dense(1,activation='sigmoid')(hidden2)\n",
    "\n",
    "    model = Model(inp,out)\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "    model.summary()\n",
    "    import time\n",
    "\n",
    "    s = time.time()\n",
    "    model.fit(X_train,Y_train,epochs = epoch,batch_size=batchsize,class_weight=class_weights)\n",
    "    e = time.time()\n",
    "    print(\"Training Time for Binary NN : \", (e - s))\n",
    "    \n",
    "    predicted = model.predict(X_test)\n",
    "    predicted = predicted.ravel()\n",
    "    #print(len(predicted))\n",
    "    Y_predicted = np.empty((len(predicted),))\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] < 0.5:\n",
    "            Y_predicted[i] = 0\n",
    "            #Y_predicted[i] = (Y_predicted[i])\n",
    "        else:\n",
    "            Y_predicted[i] = 1\n",
    "            #Y_predicted[i] = math.floor(Y_predicted[i])\n",
    "\n",
    "    Y_predicted = Y_predicted.astype(int)\n",
    "    Y_test_final = np.array(Y_test)\n",
    "    print(Y_predicted.shape)\n",
    "    print(Y_test_final.shape)\n",
    "    print(type(Y_predicted))\n",
    "    print(type(Y_test_final))\n",
    "\n",
    "    print(\"Y_predicted Unique and its Frequency :\")\n",
    "    y_pre,y_pred_counts = np.unique(Y_predicted,return_counts=True)\n",
    "    print(y_pre,y_pred_counts)\n",
    "\n",
    "    print(\"Y_test Final unique and its Frequency : \")\n",
    "    y_test_final,y_test_counts = np.unique(Y_test_final,return_counts=True)\n",
    "    print(y_test_final,y_test_counts)\n",
    "\n",
    "\n",
    "    tp,fp,tn,fn = 0,0,0,0\n",
    "    for i in range(len(Y_test_final)):\n",
    "        if Y_test_final[i] == Y_predicted[i] and Y_test_final[i] == 1:\n",
    "            tp = tp + 1\n",
    "        elif Y_test_final[i] == Y_predicted[i] and Y_test_final[i] == 0:\n",
    "            tn = tn + 1\n",
    "        elif Y_test_final[i] != Y_predicted[i] and Y_test_final[i] == 0:\n",
    "            fp = fp + 1\n",
    "        else:\n",
    "            fn = fn + 1\n",
    "\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = (2*precision*recall)/(precision + recall)\n",
    "    print(\"tp :\",tp)\n",
    "    print(\"tn :\",tn)\n",
    "    print(\"fp :\",fp)\n",
    "    print(\"fn :\",fn)\n",
    "    print(\"Accuracy : \",accuracy)\n",
    "    print(\"Precision : \",precision)\n",
    "    print(\"Recall : \",recall)\n",
    "    print(\"f1_score : \",f1_score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "for i in range(10, 31, 10):\n",
    "    new_dat = ffr(data, i)\n",
    "    print(\"features = \", i)\n",
    "    print(new_dat.shape)\n",
    "    print(type(new_dat))\n",
    "    print(\"With Feature size : \", i)\n",
    "    NN(new_dat,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"output_file\",Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted = predicted.ravel()\n",
    "# Y_test = Y_test.ravel()\n",
    "# print(predicted.shape)\n",
    "# print(Y_test.shape)\n",
    "# Y_test_final = np.empty((len(Y_test),))\n",
    "# for i in range(len(Y_test)):\n",
    "#     Y_test_final[i] = np.argmax(Y_test[i])\n",
    "\n",
    "# Y_predicted = np.empty((len(predicted),))\n",
    "# for i in range(len(predicted)):\n",
    "#     if predicted[i] < 0.5:\n",
    "#         Y_predicted[i] = int(0)\n",
    "#     else:\n",
    "#         Y_predicted[i] = int(1)\n",
    "\n",
    "# #print(Y_test_final.shape)\n",
    "# print(Y_predicted.shape)\n",
    "\n",
    "# print(\"Predicted Unique and their Freqencies : \")\n",
    "# pred,pred_count = np.unique(predicted,return_counts=True)\n",
    "# print(pred,pred_count)\n",
    "# print(\"Y_predicted Unique and its Frequency :\")\n",
    "# y_pre,y_pred_counts = np.unique(Y_predicted,return_counts=True)\n",
    "# print(y_pre,y_pred_counts)\n",
    "# print(\"Y_test unique and its Frequency : \")\n",
    "# y_test,y_test_counts = np.unique(Y_test,return_counts=True)\n",
    "# print(y_test,y_test_counts)\n",
    "# print(\"Y_test Final unique and its Frequency : \")\n",
    "# y_test_final,y_test_counts = np.unique(Y_test,return_counts=True)\n",
    "# print(y_test_final,y_test_counts)\n",
    "# #conf = confusion_matrix(Y_test,predicted)\n",
    "# conf = confusion_matrix(Y_test_final,Y_predicted)\n",
    "# print(conf)\n",
    "# precision,recall,f1,support = precision_recall_fscore_support(Y_test_final,Y_predicted)\n",
    "# print(\"Precision : \",precision)\n",
    "# print(\"Recall : \",recall)\n",
    "# print(\"f1 : \",f1)\n",
    "# print(\"Support : \",support)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
