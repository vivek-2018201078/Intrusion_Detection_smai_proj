{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"labels.csv\",sep = \":\",header = None)\n",
    "data   = pd.read_csv(\"kddcup.data_10_percent_corrected\", names = labels.iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_replace(df):\n",
    "    replacements = {\n",
    "        r'(smurf.|neptune.|back.|teardrop.|pod.|land.)' : 'dos',\n",
    "        r'(normal.)' : 'normal',\n",
    "        r'(satan.|ipsweep.|portsweep.|nmap.)' : 'probe',\n",
    "        r'(warezclient.|guess_passwd.|warezmaster.|imap.|ftp_write.|multihop.|phf.|spy.)' : 'r2l',\n",
    "        r'(buffer_overflow.|rootkit.|loadmodule.|perl.)' : 'u2r'\n",
    "    }\n",
    "    df.replace(replacements, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "cat_columns = labels.loc[labels.iloc[:,1] == \" symbolic.\",0].values\n",
    "data[cat_columns] = data[cat_columns].apply(lambda col: lb_make.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_replace(data)\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "col_to_remove = [i for i in X.columns if len(X.loc[:,i].unique()) == 1]\n",
    "a = X.drop(col_to_remove, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = np.array([variance_inflation_factor(a.values, i) for i in range(a.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(a.columns)\n",
    "Similiarity = np.zeros((size,size))\n",
    "for col1,col2 in itertools.product(range(size), range(size)):\n",
    "    pca  = PCA(n_components = 2)\n",
    "    pca.fit(a.iloc[:,[col1,col2]])\n",
    "    Similiarity[col1][col2] = np.amin(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "k = 28\n",
    "features_to_select = np.full(size, True)\n",
    "\n",
    "while k != 1:\n",
    "    t_Similiarity = copy.deepcopy(Similiarity[features_to_select])\n",
    "    index = np.argpartition(t_Similiarity, k)\n",
    "\n",
    "    min_index     = np.argmin(t_Similiarity[range(len(t_Similiarity)),index[:,k]])\n",
    "    epsilon       = t_Similiarity[min_index, k]\n",
    "    \n",
    "    features_to_select[index[min_index,:k]] = False\n",
    "    features_to_select[min_index] = True\n",
    "    \n",
    "    if((k + 1) > np.sum(features_to_select)):\n",
    "        k = np.sum(features_to_select) - 1\n",
    "        if k == 1:\n",
    "            break\n",
    "    \n",
    "    next_epsilon = float('inf')\n",
    "    while(epsilon < next_epsilon):\n",
    "        k = k - 1\n",
    "        if k == 1:\n",
    "            break\n",
    "        t_Similiarity  = Similiarity[features_to_select]\n",
    "        index          = np.argpartition(t_Similiarity, k)\n",
    "        min_index      = np.argmin(t_Similiarity[range(len(t_Similiarity)),index[:,k]])\n",
    "        next_epsilon   = t_Similiarity[min_index, k]\n",
    "\n",
    "print(np.sum(features_to_select))\n",
    "op = a.iloc[:,features_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "[[56435     0    13   440 21372]\n",
      " [ 6995   182   345     6 11947]\n",
      " [    1     0     0     0   829]\n",
      " [  120     0     6    12    92]\n",
      " [    1     2     0     0     7]]\n",
      "accuracy =  [0.7211219  0.00934531 0.         0.05217391 0.7       ]\n",
      "Precision:  [8.88012966e-01 9.89130435e-01 0.00000000e+00 2.62008734e-02\n",
      " 2.04397465e-04]\n",
      "Recall:  [0.7211219  0.00934531 0.         0.05217391 0.7       ]\n",
      "F1:  [7.95912899e-01 1.85156926e-02 0.00000000e+00 3.48837209e-02\n",
      " 4.08675599e-04]\n",
      "Accuracy overall =  0.5732098578007185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "\n",
    "def naive_bayes(X,y):\n",
    "    accuracy_total = []\n",
    "    precision_total = []\n",
    "    recall_total = []\n",
    "    f1_total = []\n",
    "    acc_overall_total = []\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train, y_train)\n",
    "    preds = mnb.predict(X_test)\n",
    "    Accuracy = accuracy_score(y_test, preds)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_test, preds)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    print(cm)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    accuracy_total.append(cm.diagonal())\n",
    "    precision_total.append(precision)\n",
    "    recall_total.append(recall)\n",
    "    f1_total.append(f1)\n",
    "    acc_overall_total.append(Accuracy)\n",
    "\n",
    "    print(\"accuracy = \", np.array(accuracy_total).mean(axis=0))\n",
    "    print('Precision: ', np.array(precision_total).mean(axis=0))\n",
    "    print('Recall: ', np.array(recall_total).mean(axis=0))\n",
    "    print('F1: ', np.array(f1_total).mean(axis=0))\n",
    "    print(\"Accuracy overall = \", np.array(acc_overall_total).mean())\n",
    "    \n",
    "    return np.array(accuracy_total).mean(axis=0), np.array(f1_total).mean(axis=0)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "original_ueq_nb_acc, original_ueq_nb_f1 = naive_bayes(op,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  [0.99984703 0.99824389 0.89628681 0.97101449 0.        ]\n",
      "Precision:  [0.99879027 0.99824389 0.9929078  0.96172249 0.        ]\n",
      "Recall:  [0.99984703 0.99824389 0.89628681 0.97101449 0.        ]\n",
      "F1:  [0.99931837 0.99824389 0.94212651 0.96634615 0.        ]\n",
      "Accuracy overall =  0.9985628257679268\n"
     ]
    }
   ],
   "source": [
    "def knn_classify(X, Y, k):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    knn.fit(X_train, y_train)\n",
    "    preds = knn.predict(X_test)\n",
    "    Accuracy = accuracy_score(y_test, preds)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_test, preds)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    print(\"accuracy = \", cm.diagonal())\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1: ', f1)\n",
    "    print(\"Accuracy overall = \", Accuracy)\n",
    "    \n",
    "    return cm.diagonal(), f1\n",
    "\n",
    "original_ueq_knn_acc, original_ueq_knn_f1 = knn_classify(op, y, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
