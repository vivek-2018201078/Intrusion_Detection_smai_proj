{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kddcup.data_10_percent_corrected')\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_index = [1,2,3,6,11,20,21]\n",
    "unique_list = []\n",
    "\n",
    "unique1 = data.iloc[:,1].unique()\n",
    "unique_list.append(unique1)\n",
    "unique2 = data.iloc[:,2].unique()\n",
    "unique_list.append(unique2)\n",
    "unique3 = data.iloc[:,3].unique()\n",
    "unique_list.append(unique3)\n",
    "unique4 = data.iloc[:,6].unique()\n",
    "unique_list.append(unique4)\n",
    "unique5 = data.iloc[:,11].unique()\n",
    "unique_list.append(unique5)\n",
    "unique6 = data.iloc[:,20].unique()\n",
    "unique_list.append(unique6)\n",
    "unique7 = data.iloc[:,21].unique()\n",
    "unique_list.append(unique7)\n",
    "#print(unique_list)\n",
    "#print(len(unique_list))\n",
    "#print(unique2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 0\n",
    "for i in range(len(unique1)):\n",
    "    data.iloc[:,1] = np.where(data.iloc[:,1]==unique1[i], value, data.iloc[:,1])\n",
    "    value = value + 1\n",
    "\n",
    "value = 0\n",
    "for i in range(len(unique2)):\n",
    "    data.iloc[:,2] = np.where(data.iloc[:,2]==unique2[i], value, data.iloc[:,2])\n",
    "    value = value + 1\n",
    "\n",
    "value = 0\n",
    "for i in range(len(unique3)):\n",
    "    data.iloc[:,3] = np.where(data.iloc[:,3]==unique3[i], value, data.iloc[:,3])\n",
    "    value = value + 1\n",
    "\n",
    "value = 0\n",
    "for i in range(len(unique4)):\n",
    "    data.iloc[:,6] = np.where(data.iloc[:,6]==unique4[i], value, data.iloc[:,6])\n",
    "    value = value + 1\n",
    "\n",
    "value = 0\n",
    "for i in range(len(unique5)):\n",
    "    data.iloc[:,11] = np.where(data.iloc[:,11]==unique5[i], value, data.iloc[:,11])\n",
    "    value = value + 1\n",
    "\n",
    "value = 0\n",
    "for i in range(len(unique6)):\n",
    "    data.iloc[:,20] = np.where(data.iloc[:,20]==unique6[i], value, data.iloc[:,20])\n",
    "    value = value + 1\n",
    "\n",
    "value = 0\n",
    "for i in range(len(unique7)):\n",
    "    data.iloc[:,21] = np.where(data.iloc[:,21]==unique7[i], value, data.iloc[:,21])\n",
    "    value = value + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['normal.' 'buffer_overflow.' 'loadmodule.' 'perl.' 'neptune.' 'smurf.'\n",
      " 'guess_passwd.' 'pod.' 'teardrop.' 'portsweep.' 'ipsweep.' 'land.'\n",
      " 'ftp_write.' 'back.' 'imap.' 'satan.' 'phf.' 'nmap.' 'multihop.'\n",
      " 'warezmaster.' 'warezclient.' 'spy.' 'rootkit.']\n",
      "494020\n",
      "['normal' 'u2r' 'DoS' 'r2l' 'probe']\n"
     ]
    }
   ],
   "source": [
    "label_values = data.iloc[:,41].unique()\n",
    "print(label_values)\n",
    "mapping = {}\n",
    "mapping['smurf.'] = 'DoS'\n",
    "mapping['neptune.'] = 'DoS'\n",
    "mapping['back.'] = 'DoS'\n",
    "mapping['satan.'] = 'probe'\n",
    "mapping['ipsweep.'] = 'probe'\n",
    "mapping['portsweep.'] = 'probe'\n",
    "mapping['warezclient.'] = 'r2l'\n",
    "mapping['teardrop.'] = 'DoS'\n",
    "mapping['pod.'] = 'DoS'\n",
    "mapping['nmap.'] = 'probe'\n",
    "mapping['guess_passwd.'] = 'r2l'\n",
    "mapping['buffer_overflow.'] = 'u2r'\n",
    "mapping['land.'] = 'DoS'\n",
    "mapping['warezmaster.'] = 'r2l'\n",
    "mapping['imap.'] = 'r2l'\n",
    "mapping['rootkit.'] = 'u2r'\n",
    "mapping['loadmodule.'] = 'u2r'\n",
    "mapping['ftp_write.'] = 'r2l'\n",
    "mapping['multihop.'] = 'r2l'\n",
    "mapping['phf.'] = 'r2l'\n",
    "mapping['perl.'] = 'u2r'\n",
    "mapping['spy.'] = 'r2l'\n",
    "mapping['normal.'] = 'normal'\n",
    "mapping['normal'] = 'normal'\n",
    "\n",
    "row_count = data.shape[0]\n",
    "print(row_count)\n",
    "label_list = []\n",
    "for i in range(row_count):\n",
    "    value = data.iloc[i][41]\n",
    "    label_list.append(mapping[value])\n",
    "\n",
    "data.drop(data.columns[41], axis=1, inplace=True)\n",
    "data.insert(41,41,value = label_list)\n",
    "\n",
    "#data.replace(to_replace = ['smurf.','neptune.','back.','teardrop.','pod.','land.'],value = 'Dos')\n",
    "#data.replace(to_replace=['satan.','ipsweep.','portsweep.','nmap.'],value = 'probe')\n",
    "#data.replace(to_replace=['spy.','phf.','multihop.','ftp_write.','imap,','warezmaster.','guess_passwd.','warezclient.'],value = 'r2l')\n",
    "#data.replace(to_replace=['loadmodule.','rootkit.','buffer_overflow.','nmap.'],value='u2r')\n",
    "#data.replace(to_replace=['normal.'],value='normal')\n",
    "\n",
    "\n",
    "#data.iloc[:,41] = data.iloc[:,41].where(data.iloc[:,41].isin(['smurf.','neptune.','back.','teardrop.','pod.','land.']),'DoS')\n",
    "#data.iloc[:,41] = data.iloc[:,41].where(data.iloc[:,41].isin(['satan.','ipsweep.','portsweep.','nmap.']),'probe')\n",
    "#data.iloc[:,41] = data.iloc[:,41].where(data.iloc[:,41].isin(['spy.','phf.','multihop.','ftp_write.','imap,','warezmaster.','guess_passwd.','warezclient.']),'r2l')\n",
    "#data.iloc[:,41] = data.iloc[:,41].where(data.iloc[:,41].isin(['loadmodule.','rootkit.','buffer_overflow.','nmap.']),'u2r')\n",
    "#data.iloc[:,41] = data.iloc[:,41].where(data.iloc[:,41].isin(['normal.']),'normal')\n",
    "\n",
    "print(data.iloc[:,41].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# data.iloc[:,41] = np.where(data.iloc[:,41] != 'normal.',1,data.iloc[:,41])\n",
    "# data.iloc[:,41] = np.where(data.iloc[:,41] == 'normal.',0,data.iloc[:,41])\n",
    "\n",
    "# data.iloc[:,41].unique()\n",
    "#print(data)\n",
    "\n",
    "data.iloc[:,41] = np.where(data.iloc[:,41] == 'normal',0,data.iloc[:,41])\n",
    "data.iloc[:,41] = np.where(data.iloc[:,41] == 'u2r',1,data.iloc[:,41])\n",
    "data.iloc[:,41] = np.where(data.iloc[:,41] == 'DoS',2,data.iloc[:,41])\n",
    "data.iloc[:,41] = np.where(data.iloc[:,41] == 'r2l',3,data.iloc[:,41])\n",
    "data.iloc[:,41] = np.where(data.iloc[:,41] == 'probe',4,data.iloc[:,41])\n",
    "\n",
    "print(data.iloc[:,41].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajat/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import class_weight\n",
    "import itertools\n",
    "import copy\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "batchsize = 32\n",
    "\n",
    "data = data.sample(frac=1,random_state=200)\n",
    "Input1 = data.iloc[:,:41]\n",
    "Output1 = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_remove = [i for i in Input1.columns if len(Input1.loc[:,i].unique()) == 1]\n",
    "a = Input1.drop(col_to_remove, axis = 1)\n",
    "size = len(a.columns)\n",
    "Similiarity = np.zeros((size,size))\n",
    "for col1,col2 in itertools.product(range(size), range(size)):\n",
    "    pca  = PCA(n_components = 2)\n",
    "    pca.fit(a.iloc[:,[col1,col2]])\n",
    "    Similiarity[col1][col2] = np.amin(pca.explained_variance_)\n",
    "\n",
    "\n",
    "k = 8\n",
    "features_to_select = np.full(size, True)\n",
    "\n",
    "while k != 1:\n",
    "    t_Similiarity = copy.deepcopy(Similiarity[features_to_select])\n",
    "    index = np.argpartition(t_Similiarity, k)\n",
    "\n",
    "    min_index     = np.argmin(t_Similiarity[range(len(t_Similiarity)),index[:,k]])\n",
    "    epsilon       = t_Similiarity[min_index, k]\n",
    "    \n",
    "    features_to_select[index[min_index,:k]] = False\n",
    "    features_to_select[min_index] = True\n",
    "    \n",
    "    if((k + 1) > np.sum(features_to_select)):\n",
    "        k = np.sum(features_to_select) - 1\n",
    "        if k == 1:\n",
    "            break\n",
    "    \n",
    "    next_epsilon = float('inf')\n",
    "    while(epsilon < next_epsilon):\n",
    "        k = k - 1\n",
    "        if k == 1:\n",
    "            break\n",
    "        t_Similiarity  = Similiarity[features_to_select]\n",
    "        index          = np.argpartition(t_Similiarity, k)\n",
    "        min_index      = np.argmin(t_Similiarity[range(len(t_Similiarity)),index[:,k]])\n",
    "        next_epsilon   = t_Similiarity[min_index, k]\n",
    "\n",
    "np.sum(features_to_select)\n",
    "Input1 = Input1.iloc[:,features_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "(494020, 31)\n",
      "(494020, 5)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(Output1)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "print(str(encoder.classes_))\n",
    "Input1 = np.array(Input1)\n",
    "Y = np_utils.to_categorical(encoded_Y)\n",
    "print(Input1.shape)\n",
    "print(Y.shape)\n",
    "#print(Output1.shape)\n",
    "print(type(Input1))\n",
    "print(type(Output1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395216, 31)\n",
      "(98804, 31)\n",
      "(395216, 5)\n",
      "(98804, 5)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "Input1 = Input1.astype(float)\n",
    "split = int(math.ceil(0.8 * len(Input1)))\n",
    "X_train = Input1[0:split]\n",
    "Y_train = Y[0:split]\n",
    "\n",
    "X_test = Input1[split:]\n",
    "Y_test = Y[split:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "flatten_Y_train = Y_train.ravel()\n",
    "class_weights = class_weight.compute_class_weight('balanced' ,np.unique(Y_train) ,flatten_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                1280      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 205       \n",
      "=================================================================\n",
      "Total params: 3,125\n",
      "Trainable params: 3,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "395216/395216 [==============================] - 41s 103us/step - loss: 0.0434\n",
      "Epoch 2/100\n",
      "395216/395216 [==============================] - 25s 63us/step - loss: 0.0284\n",
      "Epoch 3/100\n",
      "395216/395216 [==============================] - 23s 58us/step - loss: 0.0245\n",
      "Epoch 4/100\n",
      "395216/395216 [==============================] - 24s 61us/step - loss: 0.0255\n",
      "Epoch 5/100\n",
      "395216/395216 [==============================] - 33s 84us/step - loss: 0.0246\n",
      "Epoch 6/100\n",
      "395216/395216 [==============================] - 27s 67us/step - loss: 0.0264\n",
      "Epoch 7/100\n",
      "395216/395216 [==============================] - 30s 75us/step - loss: 0.0236\n",
      "Epoch 8/100\n",
      "395216/395216 [==============================] - 26s 65us/step - loss: 0.0196\n",
      "Epoch 9/100\n",
      "395216/395216 [==============================] - 28s 70us/step - loss: 0.0231\n",
      "Epoch 10/100\n",
      "395216/395216 [==============================] - 26s 66us/step - loss: 0.0217\n",
      "Epoch 11/100\n",
      "395216/395216 [==============================] - 26s 65us/step - loss: 0.0215\n",
      "Epoch 12/100\n",
      "395216/395216 [==============================] - 28s 71us/step - loss: 0.0197\n",
      "Epoch 13/100\n",
      "395216/395216 [==============================] - 29s 72us/step - loss: 0.0192\n",
      "Epoch 14/100\n",
      "395216/395216 [==============================] - 26s 65us/step - loss: 0.0232\n",
      "Epoch 15/100\n",
      "395216/395216 [==============================] - 35s 88us/step - loss: 0.0223\n",
      "Epoch 16/100\n",
      "395216/395216 [==============================] - 44s 112us/step - loss: 0.0190\n",
      "Epoch 17/100\n",
      "395216/395216 [==============================] - 45s 113us/step - loss: 0.0158\n",
      "Epoch 18/100\n",
      "395216/395216 [==============================] - 56s 142us/step - loss: 0.0185\n",
      "Epoch 19/100\n",
      "395216/395216 [==============================] - 58s 147us/step - loss: 0.0226\n",
      "Epoch 20/100\n",
      "395216/395216 [==============================] - 53s 135us/step - loss: 0.0203\n",
      "Epoch 21/100\n",
      "395216/395216 [==============================] - 55s 139us/step - loss: 0.0203\n",
      "Epoch 22/100\n",
      "395216/395216 [==============================] - 37s 94us/step - loss: 0.0182\n",
      "Epoch 23/100\n",
      "395216/395216 [==============================] - 48s 121us/step - loss: 0.0163\n",
      "Epoch 24/100\n",
      "395216/395216 [==============================] - 51s 129us/step - loss: 0.0185\n",
      "Epoch 25/100\n",
      "395216/395216 [==============================] - 46s 115us/step - loss: 0.0201\n",
      "Epoch 26/100\n",
      "395216/395216 [==============================] - 60s 151us/step - loss: 0.0163\n",
      "Epoch 27/100\n",
      "395216/395216 [==============================] - 61s 153us/step - loss: 0.0187\n",
      "Epoch 28/100\n",
      "395216/395216 [==============================] - 60s 151us/step - loss: 0.0207\n",
      "Epoch 29/100\n",
      "395216/395216 [==============================] - 59s 150us/step - loss: 0.0227\n",
      "Epoch 30/100\n",
      "395216/395216 [==============================] - 38s 96us/step - loss: 0.0221\n",
      "Epoch 31/100\n",
      "395216/395216 [==============================] - 39s 98us/step - loss: 0.0180\n",
      "Epoch 32/100\n",
      "395216/395216 [==============================] - 39s 100us/step - loss: 0.0171\n",
      "Epoch 33/100\n",
      "395216/395216 [==============================] - 42s 106us/step - loss: 0.0177\n",
      "Epoch 34/100\n",
      "395216/395216 [==============================] - 43s 108us/step - loss: 0.0192\n",
      "Epoch 35/100\n",
      "395216/395216 [==============================] - 46s 117us/step - loss: 0.0193\n",
      "Epoch 36/100\n",
      "395216/395216 [==============================] - 44s 112us/step - loss: 0.0181\n",
      "Epoch 37/100\n",
      "395216/395216 [==============================] - 52s 132us/step - loss: 0.0180\n",
      "Epoch 38/100\n",
      "395216/395216 [==============================] - 45s 114us/step - loss: 0.0207\n",
      "Epoch 39/100\n",
      "395216/395216 [==============================] - 43s 108us/step - loss: 0.0219\n",
      "Epoch 40/100\n",
      "395216/395216 [==============================] - 30s 75us/step - loss: 0.0197\n",
      "Epoch 41/100\n",
      "395216/395216 [==============================] - 28s 71us/step - loss: 0.0173\n",
      "Epoch 42/100\n",
      "395216/395216 [==============================] - 30s 77us/step - loss: 0.0199\n",
      "Epoch 43/100\n",
      "395216/395216 [==============================] - 35s 88us/step - loss: 0.0201\n",
      "Epoch 44/100\n",
      "395216/395216 [==============================] - 35s 88us/step - loss: 0.0174\n",
      "Epoch 45/100\n",
      "395216/395216 [==============================] - 35s 88us/step - loss: 0.0176\n",
      "Epoch 46/100\n",
      "395216/395216 [==============================] - 37s 92us/step - loss: 0.0173\n",
      "Epoch 47/100\n",
      "395216/395216 [==============================] - 31s 78us/step - loss: 0.0177\n",
      "Epoch 48/100\n",
      "395216/395216 [==============================] - 39s 99us/step - loss: 0.0191\n",
      "Epoch 49/100\n",
      "395216/395216 [==============================] - 47s 118us/step - loss: 0.0217\n",
      "Epoch 50/100\n",
      "395216/395216 [==============================] - 32s 82us/step - loss: 0.0167\n",
      "Epoch 51/100\n",
      "395216/395216 [==============================] - 25s 62us/step - loss: 0.0167\n",
      "Epoch 52/100\n",
      "395216/395216 [==============================] - 23s 59us/step - loss: 0.0173\n",
      "Epoch 53/100\n",
      "395216/395216 [==============================] - 24s 60us/step - loss: 0.0237\n",
      "Epoch 54/100\n",
      "395216/395216 [==============================] - 22s 55us/step - loss: 0.0180\n",
      "Epoch 55/100\n",
      "395216/395216 [==============================] - 20s 51us/step - loss: 0.0197\n",
      "Epoch 56/100\n",
      "395216/395216 [==============================] - 22s 55us/step - loss: 0.0189\n",
      "Epoch 57/100\n",
      "395216/395216 [==============================] - 23s 57us/step - loss: 0.0165\n",
      "Epoch 58/100\n",
      "395216/395216 [==============================] - 23s 58us/step - loss: 0.0159\n",
      "Epoch 59/100\n",
      "395216/395216 [==============================] - 21s 54us/step - loss: 0.0199\n",
      "Epoch 60/100\n",
      "395216/395216 [==============================] - 21s 52us/step - loss: 0.0164\n",
      "Epoch 61/100\n",
      "395216/395216 [==============================] - 23s 59us/step - loss: 0.0166\n",
      "Epoch 62/100\n",
      "395216/395216 [==============================] - 21s 53us/step - loss: 0.0180\n",
      "Epoch 63/100\n",
      "395216/395216 [==============================] - 20s 50us/step - loss: 0.0190\n",
      "Epoch 64/100\n",
      "395216/395216 [==============================] - 22s 55us/step - loss: 0.0200\n",
      "Epoch 65/100\n",
      "395216/395216 [==============================] - 20s 50us/step - loss: 0.0196\n",
      "Epoch 66/100\n",
      "395216/395216 [==============================] - 20s 50us/step - loss: 0.0209\n",
      "Epoch 67/100\n",
      "395216/395216 [==============================] - 20s 50us/step - loss: 0.0215\n",
      "Epoch 68/100\n",
      "395216/395216 [==============================] - 21s 53us/step - loss: 0.0141\n",
      "Epoch 69/100\n",
      "395216/395216 [==============================] - 20s 50us/step - loss: 0.0219\n",
      "Epoch 70/100\n",
      "395216/395216 [==============================] - 29s 73us/step - loss: 0.0185\n",
      "Epoch 71/100\n",
      "395216/395216 [==============================] - 33s 83us/step - loss: 0.0253\n",
      "Epoch 72/100\n",
      "395216/395216 [==============================] - 33s 84us/step - loss: 0.0231\n",
      "Epoch 73/100\n",
      "395216/395216 [==============================] - 33s 82us/step - loss: 0.0202\n",
      "Epoch 74/100\n",
      "395216/395216 [==============================] - 29s 74us/step - loss: 0.0179\n",
      "Epoch 75/100\n",
      "395216/395216 [==============================] - 33s 84us/step - loss: 0.0210\n",
      "Epoch 76/100\n",
      "395216/395216 [==============================] - 33s 84us/step - loss: 0.0238\n",
      "Epoch 77/100\n",
      "395216/395216 [==============================] - 32s 82us/step - loss: 0.0187\n",
      "Epoch 78/100\n",
      "395216/395216 [==============================] - 32s 81us/step - loss: 0.0184\n",
      "Epoch 79/100\n",
      "395216/395216 [==============================] - 32s 82us/step - loss: 0.0199\n",
      "Epoch 80/100\n",
      "395216/395216 [==============================] - 50s 126us/step - loss: 0.0176\n",
      "Epoch 81/100\n",
      "395216/395216 [==============================] - 34s 87us/step - loss: 0.0201\n",
      "Epoch 82/100\n",
      "395216/395216 [==============================] - 36s 92us/step - loss: 0.0163\n",
      "Epoch 83/100\n",
      "395216/395216 [==============================] - 31s 79us/step - loss: 0.0163\n",
      "Epoch 84/100\n",
      "395216/395216 [==============================] - 29s 72us/step - loss: 0.0163\n",
      "Epoch 85/100\n",
      "395216/395216 [==============================] - 25s 64us/step - loss: 0.0183\n",
      "Epoch 86/100\n",
      "395216/395216 [==============================] - 25s 63us/step - loss: 0.0179\n",
      "Epoch 87/100\n",
      "395216/395216 [==============================] - 31s 78us/step - loss: 0.0196\n",
      "Epoch 88/100\n",
      "395216/395216 [==============================] - 29s 73us/step - loss: 0.0202\n",
      "Epoch 89/100\n",
      "395216/395216 [==============================] - 28s 71us/step - loss: 0.0210\n",
      "Epoch 90/100\n",
      "395216/395216 [==============================] - 30s 77us/step - loss: 0.0193\n",
      "Epoch 91/100\n",
      "395216/395216 [==============================] - 34s 85us/step - loss: 0.0175\n",
      "Epoch 92/100\n",
      "395216/395216 [==============================] - 30s 77us/step - loss: 0.0216\n",
      "Epoch 93/100\n",
      "395216/395216 [==============================] - 35s 87us/step - loss: 0.0229\n",
      "Epoch 94/100\n",
      "395216/395216 [==============================] - 31s 77us/step - loss: 0.0216\n",
      "Epoch 95/100\n",
      "395216/395216 [==============================] - 35s 90us/step - loss: 0.0156\n",
      "Epoch 96/100\n",
      "395216/395216 [==============================] - 32s 81us/step - loss: 0.0164\n",
      "Epoch 97/100\n",
      "395216/395216 [==============================] - 33s 82us/step - loss: 0.0177\n",
      "Epoch 98/100\n",
      "395216/395216 [==============================] - 31s 80us/step - loss: 0.0199\n",
      "Epoch 99/100\n",
      "395216/395216 [==============================] - 31s 78us/step - loss: 0.0206\n",
      "Epoch 100/100\n",
      "395216/395216 [==============================] - 33s 84us/step - loss: 0.0264\n",
      "Training Time for Multi-Class NN :  3367.3937039375305\n"
     ]
    }
   ],
   "source": [
    "# Creating the NN Model\n",
    "\n",
    "inp = Input(shape=(31,))\n",
    "hidden1 = Dense(40,activation='sigmoid')(inp)\n",
    "hidden2 = Dense(40,activation='sigmoid')(hidden1)\n",
    "out = Dense(5,activation='softmax')(hidden2)\n",
    "\n",
    "model = Model(inp,out)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "model.fit(X_train,Y_train,epochs = epoch,batch_size=batchsize,class_weight=class_weights)\n",
    "end = time.time()\n",
    "print(\"Training Time for Multi-Class NN : \",(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98804, 5)\n",
      "[[9.6789181e-01 2.3124768e-12 3.0449897e-02 1.6582143e-03 3.6687744e-08]\n",
      " [1.0427010e-06 0.0000000e+00 9.9999893e-01 4.8911558e-10 2.6390121e-11]\n",
      " [1.3196403e-07 0.0000000e+00 9.9999988e-01 3.7867860e-12 2.6025282e-12]\n",
      " ...\n",
      " [9.6789181e-01 2.3124946e-12 3.0449897e-02 1.6582143e-03 3.6687879e-08]\n",
      " [9.6789181e-01 2.3124857e-12 3.0449897e-02 1.6582143e-03 3.6687879e-08]\n",
      " [9.6789181e-01 2.3124725e-12 3.0449955e-02 1.6582174e-03 3.6687812e-08]]\n",
      "[0. 2. 2. ... 0. 0. 0.]\n",
      "(98804,)\n",
      "(98804,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Y_predicted Unique and its Frequency :\n",
      "[0. 1. 2. 3. 4.] [19975     9 77825   198   797]\n",
      "Y_test Final unique and its Frequency : \n",
      "[0. 1. 2. 3. 4.] [19473    12 78253   233   833]\n",
      "[[19445     4    16     8     0]\n",
      " [    7     2     0     1     2]\n",
      " [  446     0 77806     1     0]\n",
      " [   39     3     3   188     0]\n",
      " [   38     0     0     0   795]]\n",
      "Precision :  [0.97346683 0.22222222 0.99975586 0.94949495 0.99749059]\n",
      "Recall :  [0.99856211 0.16666667 0.99428776 0.80686695 0.95438175]\n",
      "f1 :  [0.9858548  0.19047619 0.99701431 0.87238979 0.97546012]\n",
      "Support :  [19473    12 78253   233   833]\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "#predicted = predicted.ravel()\n",
    "print(predicted.shape)\n",
    "print(predicted)\n",
    "#print(len(predicted))\n",
    "Y_predicted = np.empty((len(predicted),))\n",
    "for i in range(len(predicted)):\n",
    "    Y_predicted[i] = np.argmax(predicted[i])\n",
    "\n",
    "print(Y_predicted)\n",
    "#y_pre,y_pred_counts = np.unique(Y_predicted,return_counts=True)\n",
    "#print(y_pre,y_pred_counts)\n",
    "\n",
    "# Y_predicted = Y_predicted.astype(int)\n",
    "\n",
    "\n",
    "Y_test_final = np.empty((len(Y_test),))\n",
    "for i in range(len(Y_test)):\n",
    "    Y_test_final[i] = np.argmax(Y_test[i])\n",
    "    \n",
    "    \n",
    "print(Y_predicted.shape)\n",
    "print(Y_test_final.shape)\n",
    "print(type(Y_predicted))\n",
    "print(type(Y_test_final))\n",
    "\n",
    "print(\"Y_predicted Unique and its Frequency :\")\n",
    "y_pre,y_pred_counts = np.unique(Y_predicted,return_counts=True)\n",
    "print(y_pre,y_pred_counts)\n",
    "\n",
    "print(\"Y_test Final unique and its Frequency : \")\n",
    "y_test_final,y_test_counts = np.unique(Y_test_final,return_counts=True)\n",
    "print(y_test_final,y_test_counts)\n",
    "\n",
    "conf = confusion_matrix(Y_test_final,Y_predicted)\n",
    "print(conf)\n",
    "\n",
    "precision,recall,f1,support = precision_recall_fscore_support(Y_test_final,Y_predicted)\n",
    "print(\"Precision : \",precision)\n",
    "print(\"Recall : \",recall)\n",
    "print(\"f1 : \",f1)\n",
    "print(\"Support : \",support)\n",
    "\n",
    "\n",
    "# tp,fp,tn,fn = 0,0,0,0\n",
    "# for i in range(len(Y_test_final)):\n",
    "#     if Y_test_final[i] == Y_predicted[i] and Y_test_final[i] == 1:\n",
    "#         tp = tp + 1\n",
    "#     elif Y_test_final[i] == Y_predicted[i] and Y_test_final[i] == 0:\n",
    "#         tn = tn + 1\n",
    "#     elif Y_test_final[i] != Y_predicted[i] and Y_test_final[i] == 0:\n",
    "#         fp = fp + 1\n",
    "#     else:\n",
    "#         fn = fn + 1\n",
    "\n",
    "# accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "# precision = tp/(tp+fp)\n",
    "# recall = tp/(tp+fn)\n",
    "# f1_score = (2*precision*recall)/(precision + recall)\n",
    "# print(\"tp :\",tp)\n",
    "# print(\"tn :\",tn)\n",
    "# print(\"fp :\",fp)\n",
    "# print(\"fn :\",fn)\n",
    "# print(\"Accuracy : \",accuracy)\n",
    "# print(\"Precision : \",precision)\n",
    "# print(\"Recall : \",recall)\n",
    "# print(\"f1_score : \",f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
